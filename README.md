# Shootify Color Correction23Automated color correction system for fashion imagery using deep learning. This project addresses the challenge of ensuring exact color fidelity between reference product photos and generated on-model images.45## ğŸ¯ Problem Statement67Fashion brands need to ensure that the colors in AI-generated on-model imagery match the original product photos exactly. Manual correction in Photoshop is slow, subjective, and doesn't scale. This project provides an automated solution using a lightweight U-Net model trained specifically for color correction.89## âœ¨ Key Features1011- **Fast Color Correction**: Lightweight U-Net architecture optimized for speed (2-3x faster than standard U-Net)12- **Precise Masking**: Only corrects colors in the garment region, preserving skin tones and background13- **Texture Preservation**: Maintains material texture while correcting colors14- **Mixed Precision Training**: Accelerated training using PyTorch AMP15- **Easy Inference**: Simple command-line interface for production use1617## ğŸ“‹ Requirements1819- Python 3.8+20- CUDA-capable GPU (recommended for training)21- See `requirements.txt` for full dependencies2223## ğŸš€ Quick Start2425### Installation2627```bash28# Clone the repository29git clone https://github.com/yourusername/shootify-color-correction.git30cd shootify-color-correction3132# Install dependencies33pip install -r requirements.txt34```3536### Dataset Preparation3738Your dataset should have the following structure:3940```41data/42â”œâ”€â”€ train_manifest.csv    # Columns: image, mask_npy43â””â”€â”€ test_manifest.csv     # Columns: image, mask_npy44```4546Each row in the manifest CSV should contain:47- `image`: Path to the image file (.jpg, .png)48- `mask_npy`: Path to the binary mask file (.npy) with shape [H, W]4950Example CSV:51```csv52image,mask_npy53/path/to/image1.jpg,/path/to/mask1.npy54/path/to/image2.jpg,/path/to/mask2.npy55```5657### Training5859```bash60python scripts/train.py \61    --train-manifest data/train_manifest.csv \62    --test-manifest data/test_manifest.csv \63    --epochs 10 \64    --batch-size 4 \65    --output-dir outputs66```6768**Training Configuration:**69- Default config is in `config/config.yaml`70- Training uses mixed precision (AMP) by default for 2-3x speedup71- Model checkpoints saved to `outputs/model.pth`72- Training history visualization saved to `outputs/training_history.png`7374### Evaluation7576```bash77python scripts/evaluate.py \78    --checkpoint outputs/model.pth \79    --test-manifest data/test_manifest.csv80```8182### Inference8384Run color correction on new images:8586```bash87python scripts/inference.py \88    --checkpoint outputs/model.pth \89    --degraded path/to/degraded_image.jpg \90    --mask path/to/mask.npy \91    --reference path/to/reference_image.jpg \92    --output path/to/output.jpg \93    --visualize94```9596**Arguments:**97- `--degraded`: Image with incorrect colors (the on-model image)98- `--mask`: Binary mask indicating the garment region99- `--reference`: Reference image with correct colors (still-life product photo)100- `--output`: Where to save the corrected image101- `--visualize`: Create a visualization showing before/after comparison102103## ğŸ“Š Model Architecture104105The model uses a lightweight U-Net architecture specifically optimized for color correction:106107```108Input: 7 channels (degraded RGB + mask + color conditioning RGB)109â”œâ”€â”€ Encoder: 32 â†’ 64 â†’ 128 â†’ 256 channels110â”œâ”€â”€ Bottleneck: 256 channels111â”œâ”€â”€ Decoder: 256 â†’ 128 â†’ 64 â†’ 32 channels (with skip connections)112â””â”€â”€ Output: 3 channels (RGB correction residual)113```114115**Key Design Choices:**116- **Residual Output**: Model predicts correction instead of full image for stability117- **Color Conditioning**: Reference color extracted from masked region guides correction118- **Mixed Precision**: FP16 training for 2-3x speedup with no quality loss119- **Compact Architecture**: ~50% fewer parameters than standard U-Net120121## ğŸ“ˆ Training Details122123**Loss Function:**124```125Total Loss = Global MSE + (2.0 Ã— Masked MSE)126```127- Global MSE ensures overall image quality128- Masked MSE (2x weight) focuses on garment region accuracy129130**Optimization:**131- Optimizer: AdamW (lr=1e-4, weight_decay=0.01)132- Mixed Precision: Enabled by default (PyTorch AMP)133- Batch Size: 4 (adjust based on GPU memory)134- Image Size: 256Ã—256135- Epochs: 10 (adjust based on dataset size)136137**Data Augmentation:**138- Color degradation applied during training139- Purple/magenta color shift simulates typical generative model artifacts140141## ğŸ“ Configuration142143Edit `config/config.yaml` to customize training parameters:144145```yaml146training:147  epochs: 10148  batch_size: 4149  learning_rate: 0.0001150  img_size: 256151  use_amp: true152  degradation_strength: 0.5153```154155## ğŸ¨ Evaluation Metrics156157The model is evaluated using:158- **Color Accuracy**: Mean absolute difference in masked region159- **MSE (Global)**: Overall image quality160- **MSE (Masked)**: Garment region quality161- **PSNR (Global)**: Peak signal-to-noise ratio162- **PSNR (Masked)**: PSNR in garment region163164## ğŸ“ Project Structure165166```167shootify-color-correction/168â”œâ”€â”€ config/169â”‚   â””â”€â”€ config.yaml              # Configuration file170â”œâ”€â”€ src/171â”‚   â”œâ”€â”€ models/172â”‚   â”‚   â””â”€â”€ unet.py             # U-Net model architecture173â”‚   â”œâ”€â”€ data/174â”‚   â”‚   â”œâ”€â”€ dataset.py          # Dataset class175â”‚   â”‚   â””â”€â”€ degradation.py      # Color degradation176â”‚   â”œâ”€â”€ training/177â”‚   â”‚   â”œâ”€â”€ train.py            # Training logic178â”‚   â”‚   â””â”€â”€ loss.py             # Loss functions179â”‚   â”œâ”€â”€ evaluation/180â”‚   â”‚   â”œâ”€â”€ metrics.py          # Evaluation metrics181â”‚   â”‚   â””â”€â”€ evaluate.py         # Evaluation pipeline182â”‚   â””â”€â”€ utils/183â”‚       â”œâ”€â”€ color_utils.py      # Color processing utilities184â”‚       â””â”€â”€ visualization.py    # Visualization tools185â”œâ”€â”€ scripts/186â”‚   â”œâ”€â”€ train.py                # Training script187â”‚   â”œâ”€â”€ evaluate.py             # Evaluation script188â”‚   â””â”€â”€ inference.py            # Inference script189â”œâ”€â”€ requirements.txt            # Python dependencies190â””â”€â”€ README.md                   # This file191```192193## ğŸ”§ Troubleshooting194195**Out of Memory (OOM) Errors:**196- Reduce batch size in config: `batch_size: 2`197- Reduce image size: `img_size: 192`198- Enable gradient accumulation: `gradient_accumulation: 2`199200**Slow Training:**201- Ensure AMP is enabled: `use_amp: true`202- Check GPU utilization with `nvidia-smi`203- Increase num_workers for data loading (if CPU bottleneck)204205**Poor Results:**206- Increase training epochs207- Adjust degradation strength208- Ensure masks are accurate209- Check that reference images have correct colors210211## ğŸ“„ License212213[Your License Here]214215## ğŸ™ Acknowledgments216217This project was developed as part of the Shootify coding challenge for automated fashion image processing.218219## ğŸ“§ Contact220221[Your Contact Information]222223---224225For questions or issues, please open an issue on GitHub.226